# app.py â€” Clasificador de TÃ³picos Flexible (Zeroâ€‘Shot) con Streamlit y BART-MNLI
# Autor: Tu Nombre
# DescripciÃ³n: App bonita y prÃ¡ctica para clasificar texto en categorÃ­as no vistas (zeroâ€‘shot)
# -----------------------------------------------------------------------------------------
# â–¶ Requisitos (instalar en tu entorno):
#   pip install streamlit transformers torch accelerate huggingface_hub
# â–¶ Ejecutar:
#   streamlit run app.py

import os
import platform
from typing import List

import streamlit as st
from transformers import pipeline

# ==========================
# ðŸŽ¨ Estilos sutiles (CSS)
# ==========================
CSS = """
<style>
:root { --radius: 16px; }
.block-container { padding-top: 2rem; }
.card { background: #ffffff; border-radius: var(--radius); padding: 1.25rem 1.25rem; box-shadow: 0 8px 30px rgba(0,0,0,0.06); border: 1px solid rgba(0,0,0,0.06); }
.badge { display: inline-block; padding: .25rem .6rem; border-radius: 999px; font-size: .8rem; background: #eef2ff; color: #3730a3; border: 1px solid #c7d2fe; }
.small { color: #6b7280; font-size: .9rem; }
footer { visibility: hidden; }
</style>
"""

st.set_page_config(page_title="Zeroâ€‘Shot Clasificador (BART-MNLI)", page_icon="ðŸ§ ", layout="wide")
st.markdown(CSS, unsafe_allow_html=True)

# ======================================
# âš™ï¸ Sidebar: ConfiguraciÃ³n de la app
# ======================================
st.sidebar.title("âš™ï¸ ConfiguraciÃ³n")

st.sidebar.markdown(
    "Esta app usa **Zeroâ€‘Shot Text Classification** (NLI) con el modelo\n"
    "`facebook/bart-large-mnli`. No requiere reâ€‘entrenamiento."
)

# Token opcional de Hugging Face (por si el repo necesita autenticaciÃ³n o quieres mÃ¡s velocidad)
hf_token = st.sidebar.text_input("Hugging Face Token (opcional)", type="password", help="Si lo agregas, lo uso como HF_TOKEN para la descarga del modelo.")
if hf_token:
    os.environ["HF_TOKEN"] = hf_token

model_name = st.sidebar.selectbox(
    "Modelo",
    options=["facebook/bart-large-mnli"],
    index=0,
    help="BARTâ€‘MNLI es ideal para Zeroâ€‘Shot por su entrenamiento en inferencia."
)

use_gpu = st.sidebar.checkbox("Usar GPU si estÃ¡ disponible", value=True)

st.sidebar.caption(
    f"ðŸ–¥ï¸ Sistema: {platform.system()} â€¢ Python: {platform.python_version()}"
)

# =====================================================
# ðŸ§  Carga eficiente del modelo (cacheado una sola vez)
# =====================================================
@st.cache_resource(show_spinner=True)
def load_pipeline(model_id: str, prefer_gpu: bool = True):
    """Carga el pipeline de zeroâ€‘shot con cachÃ© de recursos."""
    device_map = "auto" if prefer_gpu else None
    try:
        clf = pipeline(
            "zero-shot-classification",
            model=model_id,
            device_map=device_map,  # usa GPU si estÃ¡
        )
        return clf
    except Exception as e:
        st.error(f"No se pudo cargar el modelo: {e}")
        st.stop()

clf = load_pipeline(model_name, use_gpu)

# ======================================
# ðŸ§© Encabezado de la aplicaciÃ³n
# ======================================
st.title("ðŸ§  Clasificador de TÃ³picos Zeroâ€‘Shot")
st.markdown(
    "Convierte tu texto en **probabilidades** para etiquetas que *ni siquiera vio en el entrenamiento*.\n"
    "Basado en **NLI**: el modelo evalÃºa si el texto **implica** hipÃ³tesis del tipo â€˜Este texto trata sobre [etiqueta]â€™."
)

# ======================================
# ðŸ“ Entradas del usuario
# ======================================
with st.container():
    col1, col2 = st.columns([2,1])
    with col1:
        text = st.text_area(
            "Texto a analizar",
            value="Lionel Messi ganÃ³ el BalÃ³n de Oro y liderÃ³ a su equipo a la victoria.",
            height=160,
            placeholder="Escribe aquÃ­ el textoâ€¦",
        )
    with col2:
        labels_csv = st.text_input(
            "CategorÃ­as (separadas por comas)",
            value="deportes, polÃ­tica, economÃ­a, entretenimiento, tecnologÃ­a",
            help="Ej.: deportes, polÃ­tica, economÃ­a"
        )
        multi_label = st.toggle(
            "Permitir mÃºltiples etiquetas verdaderas (multiâ€‘label)",
            value=True,
            help="Si estÃ¡ activo, el modelo asigna probabilidades de forma independiente a cada etiqueta."
        )
        hypothesis_template = st.text_input(
            "Plantilla de hipÃ³tesis",
            value="Este texto trata sobre {}.",
            help="CÃ³mo se enuncia la hipÃ³tesis para cada etiqueta."
        )

# Sanitizar etiquetas
def parse_labels(s: str) -> List[str]:
    labels = [x.strip() for x in s.split(",") if x.strip()]
    # Eliminar duplicados preservando orden
    seen = set()
    uniq = []
    for x in labels:
        if x.lower() not in seen:
            uniq.append(x)
            seen.add(x.lower())
    return uniq

candidate_labels = parse_labels(labels_csv)

# ======================================
# â–¶ BotÃ³n de ejecuciÃ³n
# ======================================
run = st.button("ðŸš€ Clasificar", type="primary")

if run:
    if not text.strip():
        st.warning("Por favor escribe un texto para analizar.")
        st.stop()
    if not candidate_labels:
        st.warning("Agrega al menos una etiqueta.")
        st.stop()

    with st.spinner("Clasificando con BARTâ€‘MNLIâ€¦"):
        result = clf(
            sequences=text,
            candidate_labels=candidate_labels,
            multi_label=multi_label,
            hypothesis_template=hypothesis_template,
        )

    # â€˜resultâ€™ puede ser dict o lista dependiendo del batch; aquÃ­ es dict
    labels = result["labels"]
    scores = result["scores"]

    # Ordenar descendentemente
    pairs = sorted(zip(labels, scores), key=lambda x: x[1], reverse=True)
    sorted_labels, sorted_scores = zip(*pairs)

    st.subheader("Resultados")
    st.markdown("Probabilidad por etiqueta (cuanto mayor, mÃ¡s afinidad):")

    # Vista en tarjetas
    with st.container():
        st.markdown('<div class="card">', unsafe_allow_html=True)
        for lbl, sc in pairs:
            st.markdown(
                f"<span class='badge'>{lbl}</span> "
                f"<span class='small'>prob = {sc:.4f}</span>",
                unsafe_allow_html=True,
            )
        st.markdown('</div>', unsafe_allow_html=True)

    # GrÃ¡fico de barras
    st.bar_chart({"Etiqueta": list(sorted_labels), "Probabilidad": list(sorted_scores)}, x="Etiqueta", y="Probabilidad")

    # Tabla cruda
    st.dataframe({"Etiqueta": list(sorted_labels), "Probabilidad": [round(s, 6) for s in sorted_scores]}, use_container_width=True)

# ======================================
# ðŸ“Ž Tips y notas
# ======================================
with st.expander("Notas y buenas prÃ¡cticas"):
    st.markdown(
        "- **Cacheo**: Usamos `@st.cache_resource` para que el modelo se cargue una sola vez.\n"
        "- **Etiquetas**: MantÃ©n las etiquetas *cortas y claras* para mejores resultados.\n"
        "- **Multiâ€‘label**: ActÃ­valo si tu texto puede pertenecer a varias categorÃ­as a la vez.\n"
        "- **Rendimiento**: Si tienes GPU, deja marcada la opciÃ³n para acelerar la inferencia.\n"
        "- **Privacidad**: Si agregas un token de Hugging Face, solo se usa para descargar el modelo."
    )
